{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Outline\n",
    "\n",
    "1. Save and restore checkpoint file\n",
    "2. Visualize pre-trained neural network graph from file\n",
    "\n",
    "    2.1 Load from checkpoint file\n",
    "    \n",
    "    2.2 Load from protobuf file\n",
    "\n",
    "Ref:\n",
    "- [Tensorflow tutorial](https://www.tensorflow.org/programmers_guide/saved_model)\n",
    "\n",
    "- [Turotial about saving/restoring](http://cv-tricks.com/tensorflow-tutorial/save-restore-tensorflow-models-quick-complete-tutorial/)\n",
    "\n",
    "- [A really nice jupyter notebook for loading and visualization](http://nbviewer.jupyter.org/github/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb)\n",
    "- [Another save/restore example](https://blog.metaflow.fr/tensorflow-saving-restoring-and-mixing-multiple-models-c4c94d5d7125)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Save and restore checkpoint file\n",
    "\n",
    "After training your model, it would be a good idea to save your current model for the future. Or, you might start from a pre-trained model and fine-tuned it. Let's start with the regression model we have seen before. This is basically the same piece of code in the regression note. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# number of data samples\n",
    "N = 100\n",
    "true_alpha = 0.3\n",
    "true_beta = 0.1\n",
    "\n",
    "# for reproducing results\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)\n",
    "# create data for Y = 0.1X + 0.3\n",
    "x_data = np.random.rand(N)\n",
    "y_data = x_data*true_beta + true_alpha\n",
    "\n",
    "# declare variables\n",
    "alpha = tf.Variable(tf.zeros([1]), name=\"alpha\")\n",
    "beta = tf.Variable(tf.random_uniform([1], -1.0, 1.0), name=\"beta\")\n",
    "\n",
    "\n",
    "# relation between input and output\n",
    "y_hat = x_data*beta + alpha\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.square(y_hat-y_data))\n",
    "\n",
    "# create optimizer, set step size to be 0.5\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5) \n",
    "\n",
    "# The object fuction is to minimize the mean squared loss\n",
    "obj = optimizer.minimize(loss)\n",
    "\n",
    "# initializer\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the training step, we use **tf.train.Saver()** to manage the saving task. The next step is to train our model, as we have done before. The only difference here is that the total training step is changed from 201 to 25 so as to demonstrate how do we restore from a pre-trained model and continue training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:0, alpha:0.043902, beta:0.578978\n",
      "Step:1, alpha:0.051716, beta:0.546352\n",
      "Step:2, alpha:0.068628, beta:0.520940\n",
      "Step:3, alpha:0.081800, beta:0.495535\n",
      "Step:4, alpha:0.094969, beta:0.472074\n",
      "Step:5, alpha:0.107131, beta:0.449887\n",
      "Step:6, alpha:0.118632, beta:0.429057\n",
      "Step:7, alpha:0.129429, beta:0.409457\n",
      "Step:8, alpha:0.139589, beta:0.391027\n",
      "Step:9, alpha:0.149142, beta:0.373694\n",
      "Step:10, alpha:0.158127, beta:0.357394\n",
      "Step:11, alpha:0.166576, beta:0.342064\n",
      "Step:12, alpha:0.174523, beta:0.327648\n",
      "Step:13, alpha:0.181996, beta:0.314090\n",
      "Step:14, alpha:0.189024, beta:0.301339\n",
      "Step:15, alpha:0.195633, beta:0.289348\n",
      "Step:16, alpha:0.201849, beta:0.278071\n",
      "Step:17, alpha:0.207695, beta:0.267466\n",
      "Step:18, alpha:0.213192, beta:0.257492\n",
      "Step:19, alpha:0.218362, beta:0.248112\n",
      "Step:20, alpha:0.223224, beta:0.239291\n",
      "Step:21, alpha:0.227797, beta:0.230995\n",
      "Step:22, alpha:0.232097, beta:0.223194\n",
      "Step:23, alpha:0.236141, beta:0.215857\n",
      "Step:24, alpha:0.239944, beta:0.208957\n",
      "Model saved in file: model/regressionModel.ckpt\n"
     ]
    }
   ],
   "source": [
    "# declare saver\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# create and run session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(25):\n",
    "        sess.run(obj)\n",
    "        print(\"Step:%d, alpha:%f, beta:%f\" % \n",
    "              (step, sess.run(alpha), sess.run(beta)))\n",
    "    # Save the variable\n",
    "    save_path = saver.save(sess, \"model/regressionModel.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 25 training steps, we save the current training results to the file **regressionModel.ckpt** (ckpt stands for checkpoint) under **model** folder. \n",
    "\n",
    "Let's say you start to train the model before you sleep and then you wake up and see the output information. The estimation of $\\alpha$, $\\beta$ are 0.2140 and 0.2675 respectively, which may not be good enough. Fortunately, you save the variables, all you have to do is restore these variables and train the model based on the current results you have.\n",
    "\n",
    "First we reset everything to make sure that restoring works properly. We would also generate a new set of training data just to mimic the situation that you want to further fine tune your model with the newly acquired dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if variables exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha does not exist\n",
      "beta does not exist\n"
     ]
    }
   ],
   "source": [
    "if \"alpha\" in locals():\n",
    "    print(\"alpha exists\")\n",
    "else:\n",
    "    print(\"alpha does not exist\")\n",
    "    \n",
    "if \"beta\" in locals():\n",
    "    print(\"beta exists\")\n",
    "else:\n",
    "    print(\"beta does not exist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, everything disappears after we reset the notebook. Thus, we have to redefine the neural network and other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# reset the tensorflow to the default graph\n",
    "# this could solve some issues\n",
    "tf.reset_default_graph()\n",
    "\n",
    "###### Create a new dataset using Y = 0.1X + 0.3     ######\n",
    "###### We will pretend this as newly acquired data   ######\n",
    "# number of data samples\n",
    "N = 100\n",
    "true_alpha = 0.3\n",
    "true_beta = 0.1\n",
    "\n",
    "# for reproducing results\n",
    "np.random.seed(1234)\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "x_data = np.random.rand(N)\n",
    "y_data = x_data*true_beta + true_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we want to do is to restore the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declare the variables we want to restore\n",
    "alpha = tf.get_variable(\"alpha\", [1])\n",
    "beta = tf.get_variable(\"beta\", [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the here we declare alpha and beta using **tf.get_variable**. The is different from the previous code. We use **tf.get_variable** to create a containiner for restoring variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/regressionModel.ckpt\n",
      "Restored alpha: [ 0.23994417], beta: [ 0.20895666]\n",
      "Step:0, alpha:0.243521, beta:0.202468\n",
      "Step:10, alpha:0.269436, beta:0.155451\n",
      "Step:20, alpha:0.283460, beta:0.130008\n",
      "Step:30, alpha:0.291049, beta:0.116239\n",
      "Step:40, alpha:0.295156, beta:0.108788\n",
      "Step:50, alpha:0.297379, beta:0.104756\n"
     ]
    }
   ],
   "source": [
    "# relation between input and output\n",
    "y_hat = x_data*beta + alpha\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.square(y_hat-y_data))\n",
    "\n",
    "# create optimizer, set step size to be 0.5\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5) \n",
    "\n",
    "# The object fuction is to minimize the mean squared loss\n",
    "obj = optimizer.minimize(loss)\n",
    "\n",
    "# saver\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"model/regressionModel.ckpt\")\n",
    "    print(\"Restored alpha: %s, beta: %s\" % (alpha.eval(), beta.eval()) )\n",
    "    \n",
    "    for step in range(51):\n",
    "        sess.run(obj)\n",
    "        if step % 10 == 0:\n",
    "            print(\"Step:%d, alpha:%f, beta:%f\" % \n",
    "                  (step, sess.run(alpha), sess.run(beta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could check if the restored variable **alpha** and **beta** match the previous estimation results. We also see that the second estimated values of **alpha** and **beta** are closer to the true value after 50 more training steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Visualize pre-trained network graph from file\n",
    "\n",
    "Now consider another situation. Suppose we download a pre-trained model from some resources and we want to use it on our own dataset. Before restoring it, there are several things we might have interests:\n",
    "\n",
    "- How does the network look like?\n",
    "\n",
    "- What are the variables and their names?\n",
    "\n",
    "- What are the inputs and outputs?\n",
    "\n",
    "\n",
    "The good news is, we could use tensorboard to visualize the network. The bad news is, there are different ways to save and load the tensorflow graph ([source](https://stackoverflow.com/questions/38947658/tensorflow-saving-into-loading-a-graph-from-a-file)).\n",
    "\n",
    "1. Load from a checkpoint file, as we obtained previously.\n",
    "2. Load from a .pb ([protocol buffers](https://www.tensorflow.org/extend/tool_developers/)) file.\n",
    "3. Load from models created by TF-Slim\n",
    "\n",
    "In this note, I would show how to use the checkpoint and the .pb file. TF-Slim is a powerful and convenient library for handling complicated network models. However, it requires more understanding about its structure and we would discuss it in the later note."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start, we need some useful functions. These functions come from [here](http://nbviewer.jupyter.org/github/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb), which embeds tensorboard into jupyter notebook nicely so that you don't have to open another tab in the browser like we did before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# Helper functions for TF Graph visualization\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = tf.compat.as_bytes(\"<stripped %d bytes>\"%size)\n",
    "    return strip_def\n",
    "  \n",
    "def rename_nodes(graph_def, rename_func):\n",
    "    res_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = res_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        n.name = rename_func(n.name)\n",
    "        for i, s in enumerate(n.input):\n",
    "            n.input[i] = rename_func(s) if s[0]!='^' else '^'+rename_func(s[1:])\n",
    "    return res_def\n",
    "  \n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "  \n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load from the checkpoint file\n",
    "\n",
    "When saving the checkpoint file, you might notice that this creates several files. Among them, **XXXX.meta** stores information of the network graph and we could load the graph through function **tf.train.import_meta_graph**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.720028638038&quot;).pbtxt = 'node {\\n  name: &quot;zeros&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;alpha&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;alpha/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;alpha&quot;\\n  input: &quot;zeros&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@alpha&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;alpha/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;alpha&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@alpha&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: -1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;random_uniform/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 1234\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 7\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;random_uniform/max&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;random_uniform/RandomUniform&quot;\\n  input: &quot;random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;random_uniform/mul&quot;\\n  input: &quot;random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: 1\\n        }\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta&quot;\\n  input: &quot;random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;beta/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;beta&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul/x&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        tensor_content: &quot;<stripped 400 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;mul/x&quot;\\n  input: &quot;beta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;mul&quot;\\n  input: &quot;alpha/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 100\\n          }\\n        }\\n        tensor_content: &quot;<stripped 400 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;add&quot;\\n  input: &quot;sub/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Square&quot;\\n  op: &quot;Square&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mean&quot;\\n  op: &quot;Mean&quot;\\n  input: &quot;Square&quot;\\n  input: &quot;Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Fill&quot;\\n  op: &quot;Fill&quot;\\n  input: &quot;gradients/Shape&quot;\\n  input: &quot;gradients/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/Fill&quot;\\n  input: &quot;gradients/Mean_grad/Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile/multiples&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 100\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Tile&quot;\\n  op: &quot;Tile&quot;\\n  input: &quot;gradients/Mean_grad/Reshape&quot;\\n  input: &quot;gradients/Mean_grad/Tile/multiples&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tmultiples&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 100\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n          }\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape&quot;\\n  input: &quot;gradients/Mean_grad/Const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Prod_1&quot;\\n  op: &quot;Prod&quot;\\n  input: &quot;gradients/Mean_grad/Shape_1&quot;\\n  input: &quot;gradients/Mean_grad/Const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Maximum&quot;\\n  op: &quot;Maximum&quot;\\n  input: &quot;gradients/Mean_grad/Prod_1&quot;\\n  input: &quot;gradients/Mean_grad/Maximum/y&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/floordiv&quot;\\n  op: &quot;FloorDiv&quot;\\n  input: &quot;gradients/Mean_grad/Prod&quot;\\n  input: &quot;gradients/Mean_grad/Maximum&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/Cast&quot;\\n  op: &quot;Cast&quot;\\n  input: &quot;gradients/Mean_grad/floordiv&quot;\\n  attr {\\n    key: &quot;DstT&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;SrcT&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Mean_grad/truediv&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;gradients/Mean_grad/Tile&quot;\\n  input: &quot;gradients/Mean_grad/Cast&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul/x&quot;\\n  op: &quot;Const&quot;\\n  input: &quot;^gradients/Mean_grad/truediv&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 2.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Square_grad/mul/x&quot;\\n  input: &quot;sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/Square_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/Mean_grad/truediv&quot;\\n  input: &quot;gradients/Square_grad/mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 100\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 100\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Sum&quot;\\n  input: &quot;gradients/sub_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/Square_grad/mul_1&quot;\\n  input: &quot;gradients/sub_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Neg&quot;\\n  op: &quot;Neg&quot;\\n  input: &quot;gradients/sub_grad/Sum_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/sub_grad/Neg&quot;\\n  input: &quot;gradients/sub_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/sub_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/sub_grad/Reshape_1&quot;\\n  input: &quot;^gradients/sub_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/sub_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 100\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum&quot;\\n  input: &quot;gradients/add_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/sub_grad/tuple/control_dependency&quot;\\n  input: &quot;gradients/add_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/add_grad/Sum_1&quot;\\n  input: &quot;gradients/add_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/add_grad/Reshape_1&quot;\\n  input: &quot;^gradients/add_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/add_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 100\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Shape_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/BroadcastGradientArgs&quot;\\n  op: &quot;BroadcastGradientArgs&quot;\\n  input: &quot;gradients/mul_grad/Shape&quot;\\n  input: &quot;gradients/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  input: &quot;beta/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Sum&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/mul_grad/mul&quot;\\n  input: &quot;gradients/mul_grad/BroadcastGradientArgs&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/mul_grad/Sum&quot;\\n  input: &quot;gradients/mul_grad/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;mul/x&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Sum_1&quot;\\n  op: &quot;Sum&quot;\\n  input: &quot;gradients/mul_grad/mul_1&quot;\\n  input: &quot;gradients/mul_grad/BroadcastGradientArgs:1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;keep_dims&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/Reshape_1&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;gradients/mul_grad/Sum_1&quot;\\n  input: &quot;gradients/mul_grad/Shape_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/group_deps&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^gradients/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/mul_grad/Reshape_1&quot;\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/mul_grad/Reshape&quot;\\n  input: &quot;^gradients/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/mul_grad/Reshape&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;gradients/mul_grad/tuple/control_dependency_1&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;gradients/mul_grad/Reshape_1&quot;\\n  input: &quot;^gradients/mul_grad/tuple/group_deps&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@gradients/mul_grad/Reshape_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/learning_rate&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.5\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_alpha/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;alpha&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/add_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@alpha&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent/update_beta/ApplyGradientDescent&quot;\\n  op: &quot;ApplyGradientDescent&quot;\\n  input: &quot;beta&quot;\\n  input: &quot;GradientDescent/learning_rate&quot;\\n  input: &quot;gradients/mul_grad/tuple/control_dependency_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;GradientDescent&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^GradientDescent/update_alpha/ApplyGradientDescent&quot;\\n  input: &quot;^GradientDescent/update_beta/ApplyGradientDescent&quot;\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^alpha/Assign&quot;\\n  input: &quot;^beta/Assign&quot;\\n}\\nnode {\\n  name: &quot;save/Const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;model&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        string_val: &quot;alpha&quot;\\n        string_val: &quot;beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        string_val: &quot;&quot;\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/SaveV2&quot;\\n  op: &quot;SaveV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/SaveV2/tensor_names&quot;\\n  input: &quot;save/SaveV2/shape_and_slices&quot;\\n  input: &quot;alpha&quot;\\n  input: &quot;beta&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/control_dependency&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;^save/SaveV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@save/Const&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;alpha&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2/tensor_names&quot;\\n  input: &quot;save/RestoreV2/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;alpha&quot;\\n  input: &quot;save/RestoreV2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@alpha&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/tensor_names&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;beta&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n          dim {\\n            size: 1\\n          }\\n        }\\n        string_val: &quot;&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/RestoreV2_1&quot;\\n  op: &quot;RestoreV2&quot;\\n  input: &quot;save/Const&quot;\\n  input: &quot;save/RestoreV2_1/tensor_names&quot;\\n  input: &quot;save/RestoreV2_1/shape_and_slices&quot;\\n  attr {\\n    key: &quot;dtypes&quot;\\n    value {\\n      list {\\n        type: DT_FLOAT\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;beta&quot;\\n  input: &quot;save/RestoreV2_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@beta&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;save/restore_all&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^save/Assign&quot;\\n  input: &quot;^save/Assign_1&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.720028638038&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "_ = tf.train.import_meta_graph(\"model/regressionModel.ckpt.meta\")\n",
    "\n",
    "# we need graph_def for tensorboard to draw the graph\n",
    "graph_def = tf.get_default_graph().as_graph_def()\n",
    "show_graph(graph_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Load from the .pb file\n",
    "\n",
    "See appendix to learn how to save a .pb (or .pbtxt) file. As for loading, the idea is similar to loading the checkpoint file. We first construct an empty GraphDef object and load the graph information into it. Finally, we could visualize the graph using tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:800px;height:800px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.941519422287&quot;).pbtxt = 'node {\\n  name: &quot;inputs/x_input&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        dim {\\n          size: -1\\n        }\\n        dim {\\n          size: 784\\n        }\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inputs/x_img_input/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 4\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377\\\\034\\\\000\\\\000\\\\000\\\\034\\\\000\\\\000\\\\000\\\\001\\\\000\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;inputs/x_img_input&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;inputs/x_input&quot;\\n  input: &quot;inputs/x_img_input/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;keep_prob&quot;\\n  op: &quot;Placeholder&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n        unknown_rank: true\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_1/W_conv_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 1\\n          }\\n          dim {\\n            size: 32\\n          }\\n        }\\n        tensor_content: &quot;<stripped 3200 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_1/W_conv_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;conv_layer_1/W_conv_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_1/W_conv_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_1/b_conv_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 32\\n          }\\n        }\\n        tensor_content: &quot;<stripped 128 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_1/b_conv_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;conv_layer_1/b_conv_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_1/b_conv_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_1/conv2d_1&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;inputs/x_img_input&quot;\\n  input: &quot;conv_layer_1/W_conv_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;conv_layer_1/conv2d_1&quot;\\n  input: &quot;conv_layer_1/b_conv_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ReLu1&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;conv_layer_1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;max_pool_2x2_1&quot;\\n  op: &quot;MaxPool&quot;\\n  input: &quot;ReLu1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_2/W_conv_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 5\\n          }\\n          dim {\\n            size: 32\\n          }\\n          dim {\\n            size: 64\\n          }\\n        }\\n        tensor_content: &quot;<stripped 204800 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_2/W_conv_2/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;conv_layer_2/W_conv_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_2/W_conv_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_2/b_conv_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 64\\n          }\\n        }\\n        tensor_content: &quot;<stripped 256 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_2/b_conv_2/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;conv_layer_2/b_conv_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@conv_layer_2/b_conv_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_2/conv2d_2&quot;\\n  op: &quot;Conv2D&quot;\\n  input: &quot;max_pool_2x2_1&quot;\\n  input: &quot;conv_layer_2/W_conv_2/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 1\\n        i: 1\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_cudnn_on_gpu&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;conv_layer_2/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;conv_layer_2/conv2d_2&quot;\\n  input: &quot;conv_layer_2/b_conv_2/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ReLU2&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;conv_layer_2/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;max_pool_2x2_2&quot;\\n  op: &quot;MaxPool&quot;\\n  input: &quot;ReLU2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;data_format&quot;\\n    value {\\n      s: &quot;NHWC&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;ksize&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;padding&quot;\\n    value {\\n      s: &quot;SAME&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;strides&quot;\\n    value {\\n      list {\\n        i: 1\\n        i: 2\\n        i: 2\\n        i: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape/shape&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n          dim {\\n            size: 2\\n          }\\n        }\\n        tensor_content: &quot;\\\\377\\\\377\\\\377\\\\377@\\\\014\\\\000\\\\000&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Reshape&quot;\\n  op: &quot;Reshape&quot;\\n  input: &quot;max_pool_2x2_2&quot;\\n  input: &quot;Reshape/shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tshape&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/W_fc_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 3136\\n          }\\n          dim {\\n            size: 1024\\n          }\\n        }\\n        tensor_content: &quot;<stripped 12845056 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/W_fc_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;fc_layer_1/W_fc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/W_fc_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/b_fc_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1024\\n          }\\n        }\\n        tensor_content: &quot;<stripped 4096 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/b_fc_1/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;fc_layer_1/b_fc_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_1/b_fc_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;Reshape&quot;\\n  input: &quot;fc_layer_1/W_fc_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_1/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;fc_layer_1/MatMul&quot;\\n  input: &quot;fc_layer_1/b_fc_1/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ReLU3&quot;\\n  op: &quot;Relu&quot;\\n  input: &quot;fc_layer_1/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/Shape&quot;\\n  op: &quot;Shape&quot;\\n  input: &quot;ReLU3&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;out_type&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/random_uniform/min&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 0.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/random_uniform/max&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n        }\\n        float_val: 1.0\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/random_uniform/RandomUniform&quot;\\n  op: &quot;RandomUniform&quot;\\n  input: &quot;dropout/Shape&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;seed&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n  attr {\\n    key: &quot;seed2&quot;\\n    value {\\n      i: 0\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/random_uniform/sub&quot;\\n  op: &quot;Sub&quot;\\n  input: &quot;dropout/random_uniform/max&quot;\\n  input: &quot;dropout/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/random_uniform/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dropout/random_uniform/RandomUniform&quot;\\n  input: &quot;dropout/random_uniform/sub&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/random_uniform&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;dropout/random_uniform/mul&quot;\\n  input: &quot;dropout/random_uniform/min&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/add&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;keep_prob&quot;\\n  input: &quot;dropout/random_uniform&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/Floor&quot;\\n  op: &quot;Floor&quot;\\n  input: &quot;dropout/add&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/div&quot;\\n  op: &quot;RealDiv&quot;\\n  input: &quot;ReLU3&quot;\\n  input: &quot;keep_prob&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;dropout/mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;dropout/div&quot;\\n  input: &quot;dropout/Floor&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_2/W_fc_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 1024\\n          }\\n          dim {\\n            size: 10\\n          }\\n        }\\n        tensor_content: &quot;<stripped 40960 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_2/W_fc_2/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;fc_layer_2/W_fc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_2/W_fc_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_2/b_fc_2&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_FLOAT\\n        tensor_shape {\\n          dim {\\n            size: 10\\n          }\\n        }\\n        tensor_content: &quot;<stripped 40 bytes>&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_2/b_fc_2/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;fc_layer_2/b_fc_2&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@fc_layer_2/b_fc_2&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_2/MatMul&quot;\\n  op: &quot;MatMul&quot;\\n  input: &quot;dropout/mul&quot;\\n  input: &quot;fc_layer_2/W_fc_2/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_a&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n  attr {\\n    key: &quot;transpose_b&quot;\\n    value {\\n      b: false\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;fc_layer_2/logits_output&quot;\\n  op: &quot;Add&quot;\\n  input: &quot;fc_layer_2/MatMul&quot;\\n  input: &quot;fc_layer_2/b_fc_2/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax/dimension&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;ArgMax&quot;\\n  op: &quot;ArgMax&quot;\\n  input: &quot;fc_layer_2/logits_output&quot;\\n  input: &quot;ArgMax/dimension&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_FLOAT\\n    }\\n  }\\n  attr {\\n    key: &quot;Tidx&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.941519422287&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "graph_def = tf.GraphDef()\n",
    "with open(\"model/CNN.pb\", \"rb\") as f:\n",
    "    graph_def.ParseFromString(f.read())\n",
    "    \n",
    "show_graph(graph_def)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we could import the graph using **import_graph_def** and we could print out all the operations defined in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import/inputs/x_input Placeholder\n",
      "import/inputs/x_img_input/shape Const\n",
      "import/inputs/x_img_input Reshape\n",
      "import/keep_prob Placeholder\n",
      "import/conv_layer_1/W_conv_1 Const\n",
      "import/conv_layer_1/W_conv_1/read Identity\n",
      "import/conv_layer_1/b_conv_1 Const\n",
      "import/conv_layer_1/b_conv_1/read Identity\n",
      "import/conv_layer_1/conv2d_1 Conv2D\n",
      "import/conv_layer_1/add Add\n",
      "import/ReLu1 Relu\n",
      "import/max_pool_2x2_1 MaxPool\n",
      "import/conv_layer_2/W_conv_2 Const\n",
      "import/conv_layer_2/W_conv_2/read Identity\n",
      "import/conv_layer_2/b_conv_2 Const\n",
      "import/conv_layer_2/b_conv_2/read Identity\n",
      "import/conv_layer_2/conv2d_2 Conv2D\n",
      "import/conv_layer_2/add Add\n",
      "import/ReLU2 Relu\n",
      "import/max_pool_2x2_2 MaxPool\n",
      "import/Reshape/shape Const\n",
      "import/Reshape Reshape\n",
      "import/fc_layer_1/W_fc_1 Const\n",
      "import/fc_layer_1/W_fc_1/read Identity\n",
      "import/fc_layer_1/b_fc_1 Const\n",
      "import/fc_layer_1/b_fc_1/read Identity\n",
      "import/fc_layer_1/MatMul MatMul\n",
      "import/fc_layer_1/add Add\n",
      "import/ReLU3 Relu\n",
      "import/dropout/Shape Shape\n",
      "import/dropout/random_uniform/min Const\n",
      "import/dropout/random_uniform/max Const\n",
      "import/dropout/random_uniform/RandomUniform RandomUniform\n",
      "import/dropout/random_uniform/sub Sub\n",
      "import/dropout/random_uniform/mul Mul\n",
      "import/dropout/random_uniform Add\n",
      "import/dropout/add Add\n",
      "import/dropout/Floor Floor\n",
      "import/dropout/div RealDiv\n",
      "import/dropout/mul Mul\n",
      "import/fc_layer_2/W_fc_2 Const\n",
      "import/fc_layer_2/W_fc_2/read Identity\n",
      "import/fc_layer_2/b_fc_2 Const\n",
      "import/fc_layer_2/b_fc_2/read Identity\n",
      "import/fc_layer_2/MatMul MatMul\n",
      "import/fc_layer_2/logits_output Add\n",
      "import/ArgMax/dimension Const\n",
      "import/ArgMax ArgMax\n"
     ]
    }
   ],
   "source": [
    "tf.import_graph_def(graph_def)\n",
    "graph = tf.get_default_graph()\n",
    "# this prints all the operation names\n",
    "for op in graph.get_operations():\n",
    "    print(\"{} {}\".format(op.name, op.type) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, from my understanding, the .pb file aims for production. This indicates that it is designed for conducting prediction and it cannot be fine-tuned. \n",
    "\n",
    "Thus, let's pretend that we have a new set of data and we would like to evaluate the model on the new dataset. From the graph we know that we are looking for **x_input** and **ArgMax** for our inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# pretend we get new data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9565\n"
     ]
    }
   ],
   "source": [
    "x_input = graph.get_tensor_by_name(\"import/inputs/x_input:0\")\n",
    "ArgMax = graph.get_tensor_by_name(\"import/ArgMax:0\")\n",
    "keep_prob = graph.get_tensor_by_name(\"import/keep_prob:0\")\n",
    "y_input = tf.placeholder(tf.float32, [None, 10], name=\"y_input\")\n",
    "\n",
    "# calculate prediction accuracy\n",
    "correct_prediction = tf.equal(ArgMax, \n",
    "                              tf.argmax(y_input, 1)  )\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    batch_img, batch_label = mnist.train.next_batch(100)\n",
    "        \n",
    "    print(sess.run(accuracy, \n",
    "                    feed_dict={x_input: mnist.test.images, \n",
    "                               y_input: mnist.test.labels,\n",
    "                               keep_prob: 0.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain about 95% accuracy here, which is similar to the training accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix saving the CNN using .pb file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "0.0949\n",
      "0.4977\n",
      "0.7395\n",
      "0.8148\n",
      "0.8475\n",
      "0.87\n",
      "0.8805\n",
      "0.9001\n",
      "0.9032\n",
      "0.9113\n",
      "0.915\n",
      "0.9245\n",
      "0.9272\n",
      "0.9346\n",
      "0.9359\n",
      "0.939\n",
      "0.9403\n",
      "0.9454\n",
      "0.9457\n",
      "0.9484\n",
      "INFO:tensorflow:Froze 8 variables.\n",
      "Converted 8 variables to const ops.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.framework.graph_util import convert_variables_to_constants\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
    "\n",
    "def weight_variable(shape, suffix=None):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    if suffix:\n",
    "        name = \"W\" + suffix\n",
    "    else:\n",
    "        name = None\n",
    "        \n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "\n",
    "def bias_variable(shape, suffix=None):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "\n",
    "    if suffix:\n",
    "        name = \"b\" + suffix\n",
    "    else:\n",
    "        name = None\n",
    "        \n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "\n",
    "def conv2d(x, W, suffix=None):\n",
    "    if suffix:\n",
    "        name = \"conv2d\" + suffix\n",
    "    else:\n",
    "        name = None\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name=name)\n",
    "\n",
    "\n",
    "def max_pool_2x2(x, suffix=None):\n",
    "    if suffix:\n",
    "        name = \"max_pool_2x2\" + suffix\n",
    "    else:\n",
    "        name = None\n",
    "    \n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME', name=name)\n",
    "\n",
    "\n",
    "\n",
    "# reset the tensorflow to the default graph\n",
    "# this could solve some issues\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# input variables\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    x_input = tf.placeholder(tf.float32, [None, 784], name=\"x_input\")\n",
    "    y_input = tf.placeholder(tf.float32, [None, 10], name=\"y_input\")\n",
    "    x_img_input = tf.reshape(x_input, [-1, 28, 28, 1], name=\"x_img_input\")\n",
    "\n",
    "# dropout setting\n",
    "keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")\n",
    "\n",
    "# parameters for conv_1\n",
    "with tf.name_scope(\"conv_layer_1\"):\n",
    "    W_conv_1 = weight_variable([5, 5, 1, 32], suffix=\"_conv_1\")\n",
    "    b_conv_1 = bias_variable([32], suffix=\"_conv_1\")\n",
    "    conv_1 = conv2d(x_img_input, W_conv_1, suffix=\"_1\") + b_conv_1\n",
    "    \n",
    "ReLU_1 = tf.nn.relu(conv_1, name=\"ReLu1\")\n",
    "pool_1 = max_pool_2x2(ReLU_1, suffix=\"_1\")\n",
    "\n",
    "# parameters for conv_2\n",
    "with tf.name_scope(\"conv_layer_2\"):\n",
    "    W_conv_2 = weight_variable([5, 5, 32, 64], suffix=\"_conv_2\")\n",
    "    b_conv_2 = bias_variable([64], suffix=\"_conv_2\")\n",
    "\n",
    "    conv_2 = conv2d(pool_1, W_conv_2, suffix=\"_2\") + b_conv_2\n",
    "    \n",
    "ReLU_2 = tf.nn.relu(conv_2, name=\"ReLU2\")\n",
    "pool_2 = max_pool_2x2(ReLU_2, suffix=\"_2\")\n",
    "\n",
    "reshape = tf.reshape(pool_2, [-1, 7*7*64])\n",
    "\n",
    "# parameters for fc_1\n",
    "with tf.name_scope(\"fc_layer_1\"):\n",
    "    W_fc_1 = weight_variable([7*7*64, 1024], suffix=\"_fc_1\")\n",
    "    b_fc_1 = bias_variable([1024], suffix=\"_fc_1\")\n",
    "    fc_1 = tf.matmul(reshape, W_fc_1) + b_fc_1\n",
    "    \n",
    "ReLU_3 = tf.nn.relu(fc_1, name=\"ReLU3\")\n",
    "dropout = tf.nn.dropout(ReLU_3, keep_prob, name=\"dropout\")\n",
    "\n",
    "# parameters for fc_2\n",
    "with tf.name_scope(\"fc_layer_2\"):\n",
    "    W_fc_2 = weight_variable([1024, 10], suffix=\"_fc_2\")\n",
    "    b_fc_2 = bias_variable([10], suffix=\"_fc_2\")\n",
    "    y_logits = tf.add(tf.matmul(dropout, W_fc_2), b_fc_2, name=\"logits_output\")\n",
    "    \n",
    "\n",
    "# loss\n",
    "with tf.name_scope(\"cross_entropy\"):\n",
    "    cross_entropy = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=y_input, \n",
    "                                                logits=y_logits))\n",
    "# minimizaer to minimize cross_entropy\n",
    "obj = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# calculate prediction accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y_logits, 1), \n",
    "                              tf.argmax(y_input, 1)  )\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "graph_def = tf.get_default_graph().as_graph_def()\n",
    "\n",
    "# this one is tricky....\n",
    "output_node_names = \"ArgMax\"\n",
    "\n",
    "# start session and run\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "        batch_img, batch_label = mnist.train.next_batch(100)\n",
    "        sess.run(obj, feed_dict={x_input: batch_img, \n",
    "                                 y_input: batch_label, \n",
    "                                 keep_prob: 0.5} )\n",
    "        if i % 50 == 0:\n",
    "            print(sess.run(accuracy, \n",
    "                           feed_dict={x_input: mnist.test.images, \n",
    "                                      y_input: mnist.test.labels,\n",
    "                                      keep_prob: 0.5}))\n",
    "    # save the model\n",
    "    freeze_model = convert_variables_to_constants( \n",
    "                    sess,\n",
    "                    graph_def,\n",
    "                    output_node_names.split(\",\"))\n",
    "        \n",
    "    # save in binary format\n",
    "    tf.train.write_graph(freeze_model, \n",
    "                         \"model\", \n",
    "                         \"CNN.pb\", \n",
    "                         as_text=False)\n",
    "\n",
    "    # save in txt format\n",
    "    tf.train.write_graph(freeze_model, \n",
    "                         \"model\", \n",
    "                         \"CNN.pbtxt\", \n",
    "                         as_text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save two kinds of files here. One is .pb file, which uses binary format  with smaller file size. The other is .pbtxt file. The file size would be larger but is human-readable. \n",
    "\n",
    "The .pb file is designed for production. This would exclude some unnecessary meta files. In tensorflow, this is called \"freezing\". To freeze the model, we have to convert variables to constants. Tensorflow provides an API for doing this. However, there is one tricky part: find out the **output_node_names**, which depends on your network graph structure. Normally, when doing classification, the output node should be **argmax**, **softmax** or something related to these neames.\n",
    "\n",
    "Here is a useful code to list all of the node names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'inputs/x_input',\n",
       " u'inputs/y_input',\n",
       " u'inputs/x_img_input/shape',\n",
       " u'inputs/x_img_input',\n",
       " u'keep_prob',\n",
       " u'conv_layer_1/truncated_normal/shape',\n",
       " u'conv_layer_1/truncated_normal/mean',\n",
       " u'conv_layer_1/truncated_normal/stddev',\n",
       " u'conv_layer_1/truncated_normal/TruncatedNormal',\n",
       " u'conv_layer_1/truncated_normal/mul',\n",
       " u'conv_layer_1/truncated_normal',\n",
       " u'conv_layer_1/W_conv_1',\n",
       " u'conv_layer_1/W_conv_1/Assign',\n",
       " u'conv_layer_1/W_conv_1/read',\n",
       " u'conv_layer_1/Const',\n",
       " u'conv_layer_1/b_conv_1',\n",
       " u'conv_layer_1/b_conv_1/Assign',\n",
       " u'conv_layer_1/b_conv_1/read',\n",
       " u'conv_layer_1/conv2d_1',\n",
       " u'conv_layer_1/add',\n",
       " u'ReLu1',\n",
       " u'max_pool_2x2_1',\n",
       " u'conv_layer_2/truncated_normal/shape',\n",
       " u'conv_layer_2/truncated_normal/mean',\n",
       " u'conv_layer_2/truncated_normal/stddev',\n",
       " u'conv_layer_2/truncated_normal/TruncatedNormal',\n",
       " u'conv_layer_2/truncated_normal/mul',\n",
       " u'conv_layer_2/truncated_normal',\n",
       " u'conv_layer_2/W_conv_2',\n",
       " u'conv_layer_2/W_conv_2/Assign',\n",
       " u'conv_layer_2/W_conv_2/read',\n",
       " u'conv_layer_2/Const',\n",
       " u'conv_layer_2/b_conv_2',\n",
       " u'conv_layer_2/b_conv_2/Assign',\n",
       " u'conv_layer_2/b_conv_2/read',\n",
       " u'conv_layer_2/conv2d_2',\n",
       " u'conv_layer_2/add',\n",
       " u'ReLU2',\n",
       " u'max_pool_2x2_2',\n",
       " u'Reshape/shape',\n",
       " u'Reshape',\n",
       " u'fc_layer_1/truncated_normal/shape',\n",
       " u'fc_layer_1/truncated_normal/mean',\n",
       " u'fc_layer_1/truncated_normal/stddev',\n",
       " u'fc_layer_1/truncated_normal/TruncatedNormal',\n",
       " u'fc_layer_1/truncated_normal/mul',\n",
       " u'fc_layer_1/truncated_normal',\n",
       " u'fc_layer_1/W_fc_1',\n",
       " u'fc_layer_1/W_fc_1/Assign',\n",
       " u'fc_layer_1/W_fc_1/read',\n",
       " u'fc_layer_1/Const',\n",
       " u'fc_layer_1/b_fc_1',\n",
       " u'fc_layer_1/b_fc_1/Assign',\n",
       " u'fc_layer_1/b_fc_1/read',\n",
       " u'fc_layer_1/MatMul',\n",
       " u'fc_layer_1/add',\n",
       " u'ReLU3',\n",
       " u'dropout/Shape',\n",
       " u'dropout/random_uniform/min',\n",
       " u'dropout/random_uniform/max',\n",
       " u'dropout/random_uniform/RandomUniform',\n",
       " u'dropout/random_uniform/sub',\n",
       " u'dropout/random_uniform/mul',\n",
       " u'dropout/random_uniform',\n",
       " u'dropout/add',\n",
       " u'dropout/Floor',\n",
       " u'dropout/div',\n",
       " u'dropout/mul',\n",
       " u'fc_layer_2/truncated_normal/shape',\n",
       " u'fc_layer_2/truncated_normal/mean',\n",
       " u'fc_layer_2/truncated_normal/stddev',\n",
       " u'fc_layer_2/truncated_normal/TruncatedNormal',\n",
       " u'fc_layer_2/truncated_normal/mul',\n",
       " u'fc_layer_2/truncated_normal',\n",
       " u'fc_layer_2/W_fc_2',\n",
       " u'fc_layer_2/W_fc_2/Assign',\n",
       " u'fc_layer_2/W_fc_2/read',\n",
       " u'fc_layer_2/Const',\n",
       " u'fc_layer_2/b_fc_2',\n",
       " u'fc_layer_2/b_fc_2/Assign',\n",
       " u'fc_layer_2/b_fc_2/read',\n",
       " u'fc_layer_2/MatMul',\n",
       " u'fc_layer_2/logits_output',\n",
       " u'cross_entropy/Rank',\n",
       " u'cross_entropy/Shape',\n",
       " u'cross_entropy/Rank_1',\n",
       " u'cross_entropy/Shape_1',\n",
       " u'cross_entropy/Sub/y',\n",
       " u'cross_entropy/Sub',\n",
       " u'cross_entropy/Slice/begin',\n",
       " u'cross_entropy/Slice/size',\n",
       " u'cross_entropy/Slice',\n",
       " u'cross_entropy/concat/values_0',\n",
       " u'cross_entropy/concat/axis',\n",
       " u'cross_entropy/concat',\n",
       " u'cross_entropy/Reshape',\n",
       " u'cross_entropy/Rank_2',\n",
       " u'cross_entropy/Shape_2',\n",
       " u'cross_entropy/Sub_1/y',\n",
       " u'cross_entropy/Sub_1',\n",
       " u'cross_entropy/Slice_1/begin',\n",
       " u'cross_entropy/Slice_1/size',\n",
       " u'cross_entropy/Slice_1',\n",
       " u'cross_entropy/concat_1/values_0',\n",
       " u'cross_entropy/concat_1/axis',\n",
       " u'cross_entropy/concat_1',\n",
       " u'cross_entropy/Reshape_1',\n",
       " u'cross_entropy/SoftmaxCrossEntropyWithLogits',\n",
       " u'cross_entropy/Sub_2/y',\n",
       " u'cross_entropy/Sub_2',\n",
       " u'cross_entropy/Slice_2/begin',\n",
       " u'cross_entropy/Slice_2/size',\n",
       " u'cross_entropy/Slice_2',\n",
       " u'cross_entropy/Reshape_2',\n",
       " u'cross_entropy/Const',\n",
       " u'cross_entropy/Mean',\n",
       " u'gradients/Shape',\n",
       " u'gradients/Const',\n",
       " u'gradients/Fill',\n",
       " u'gradients/cross_entropy/Mean_grad/Reshape/shape',\n",
       " u'gradients/cross_entropy/Mean_grad/Reshape',\n",
       " u'gradients/cross_entropy/Mean_grad/Shape',\n",
       " u'gradients/cross_entropy/Mean_grad/Tile',\n",
       " u'gradients/cross_entropy/Mean_grad/Shape_1',\n",
       " u'gradients/cross_entropy/Mean_grad/Shape_2',\n",
       " u'gradients/cross_entropy/Mean_grad/Const',\n",
       " u'gradients/cross_entropy/Mean_grad/Prod',\n",
       " u'gradients/cross_entropy/Mean_grad/Const_1',\n",
       " u'gradients/cross_entropy/Mean_grad/Prod_1',\n",
       " u'gradients/cross_entropy/Mean_grad/Maximum/y',\n",
       " u'gradients/cross_entropy/Mean_grad/Maximum',\n",
       " u'gradients/cross_entropy/Mean_grad/floordiv',\n",
       " u'gradients/cross_entropy/Mean_grad/Cast',\n",
       " u'gradients/cross_entropy/Mean_grad/truediv',\n",
       " u'gradients/cross_entropy/Reshape_2_grad/Shape',\n",
       " u'gradients/cross_entropy/Reshape_2_grad/Reshape',\n",
       " u'gradients/zeros_like',\n",
       " u'gradients/cross_entropy/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim',\n",
       " u'gradients/cross_entropy/SoftmaxCrossEntropyWithLogits_grad/ExpandDims',\n",
       " u'gradients/cross_entropy/SoftmaxCrossEntropyWithLogits_grad/mul',\n",
       " u'gradients/cross_entropy/Reshape_grad/Shape',\n",
       " u'gradients/cross_entropy/Reshape_grad/Reshape',\n",
       " u'gradients/fc_layer_2/logits_output_grad/Shape',\n",
       " u'gradients/fc_layer_2/logits_output_grad/Shape_1',\n",
       " u'gradients/fc_layer_2/logits_output_grad/BroadcastGradientArgs',\n",
       " u'gradients/fc_layer_2/logits_output_grad/Sum',\n",
       " u'gradients/fc_layer_2/logits_output_grad/Reshape',\n",
       " u'gradients/fc_layer_2/logits_output_grad/Sum_1',\n",
       " u'gradients/fc_layer_2/logits_output_grad/Reshape_1',\n",
       " u'gradients/fc_layer_2/logits_output_grad/tuple/group_deps',\n",
       " u'gradients/fc_layer_2/logits_output_grad/tuple/control_dependency',\n",
       " u'gradients/fc_layer_2/logits_output_grad/tuple/control_dependency_1',\n",
       " u'gradients/fc_layer_2/MatMul_grad/MatMul',\n",
       " u'gradients/fc_layer_2/MatMul_grad/MatMul_1',\n",
       " u'gradients/fc_layer_2/MatMul_grad/tuple/group_deps',\n",
       " u'gradients/fc_layer_2/MatMul_grad/tuple/control_dependency',\n",
       " u'gradients/fc_layer_2/MatMul_grad/tuple/control_dependency_1',\n",
       " u'gradients/dropout/mul_grad/Shape',\n",
       " u'gradients/dropout/mul_grad/Shape_1',\n",
       " u'gradients/dropout/mul_grad/BroadcastGradientArgs',\n",
       " u'gradients/dropout/mul_grad/mul',\n",
       " u'gradients/dropout/mul_grad/Sum',\n",
       " u'gradients/dropout/mul_grad/Reshape',\n",
       " u'gradients/dropout/mul_grad/mul_1',\n",
       " u'gradients/dropout/mul_grad/Sum_1',\n",
       " u'gradients/dropout/mul_grad/Reshape_1',\n",
       " u'gradients/dropout/mul_grad/tuple/group_deps',\n",
       " u'gradients/dropout/mul_grad/tuple/control_dependency',\n",
       " u'gradients/dropout/mul_grad/tuple/control_dependency_1',\n",
       " u'gradients/dropout/div_grad/Shape',\n",
       " u'gradients/dropout/div_grad/Shape_1',\n",
       " u'gradients/dropout/div_grad/BroadcastGradientArgs',\n",
       " u'gradients/dropout/div_grad/RealDiv',\n",
       " u'gradients/dropout/div_grad/Sum',\n",
       " u'gradients/dropout/div_grad/Reshape',\n",
       " u'gradients/dropout/div_grad/Neg',\n",
       " u'gradients/dropout/div_grad/RealDiv_1',\n",
       " u'gradients/dropout/div_grad/RealDiv_2',\n",
       " u'gradients/dropout/div_grad/mul',\n",
       " u'gradients/dropout/div_grad/Sum_1',\n",
       " u'gradients/dropout/div_grad/Reshape_1',\n",
       " u'gradients/dropout/div_grad/tuple/group_deps',\n",
       " u'gradients/dropout/div_grad/tuple/control_dependency',\n",
       " u'gradients/dropout/div_grad/tuple/control_dependency_1',\n",
       " u'gradients/ReLU3_grad/ReluGrad',\n",
       " u'gradients/fc_layer_1/add_grad/Shape',\n",
       " u'gradients/fc_layer_1/add_grad/Shape_1',\n",
       " u'gradients/fc_layer_1/add_grad/BroadcastGradientArgs',\n",
       " u'gradients/fc_layer_1/add_grad/Sum',\n",
       " u'gradients/fc_layer_1/add_grad/Reshape',\n",
       " u'gradients/fc_layer_1/add_grad/Sum_1',\n",
       " u'gradients/fc_layer_1/add_grad/Reshape_1',\n",
       " u'gradients/fc_layer_1/add_grad/tuple/group_deps',\n",
       " u'gradients/fc_layer_1/add_grad/tuple/control_dependency',\n",
       " u'gradients/fc_layer_1/add_grad/tuple/control_dependency_1',\n",
       " u'gradients/fc_layer_1/MatMul_grad/MatMul',\n",
       " u'gradients/fc_layer_1/MatMul_grad/MatMul_1',\n",
       " u'gradients/fc_layer_1/MatMul_grad/tuple/group_deps',\n",
       " u'gradients/fc_layer_1/MatMul_grad/tuple/control_dependency',\n",
       " u'gradients/fc_layer_1/MatMul_grad/tuple/control_dependency_1',\n",
       " u'gradients/Reshape_grad/Shape',\n",
       " u'gradients/Reshape_grad/Reshape',\n",
       " u'gradients/max_pool_2x2_2_grad/MaxPoolGrad',\n",
       " u'gradients/ReLU2_grad/ReluGrad',\n",
       " u'gradients/conv_layer_2/add_grad/Shape',\n",
       " u'gradients/conv_layer_2/add_grad/Shape_1',\n",
       " u'gradients/conv_layer_2/add_grad/BroadcastGradientArgs',\n",
       " u'gradients/conv_layer_2/add_grad/Sum',\n",
       " u'gradients/conv_layer_2/add_grad/Reshape',\n",
       " u'gradients/conv_layer_2/add_grad/Sum_1',\n",
       " u'gradients/conv_layer_2/add_grad/Reshape_1',\n",
       " u'gradients/conv_layer_2/add_grad/tuple/group_deps',\n",
       " u'gradients/conv_layer_2/add_grad/tuple/control_dependency',\n",
       " u'gradients/conv_layer_2/add_grad/tuple/control_dependency_1',\n",
       " u'gradients/conv_layer_2/conv2d_2_grad/Shape',\n",
       " u'gradients/conv_layer_2/conv2d_2_grad/Conv2DBackpropInput',\n",
       " u'gradients/conv_layer_2/conv2d_2_grad/Shape_1',\n",
       " u'gradients/conv_layer_2/conv2d_2_grad/Conv2DBackpropFilter',\n",
       " u'gradients/conv_layer_2/conv2d_2_grad/tuple/group_deps',\n",
       " u'gradients/conv_layer_2/conv2d_2_grad/tuple/control_dependency',\n",
       " u'gradients/conv_layer_2/conv2d_2_grad/tuple/control_dependency_1',\n",
       " u'gradients/max_pool_2x2_1_grad/MaxPoolGrad',\n",
       " u'gradients/ReLu1_grad/ReluGrad',\n",
       " u'gradients/conv_layer_1/add_grad/Shape',\n",
       " u'gradients/conv_layer_1/add_grad/Shape_1',\n",
       " u'gradients/conv_layer_1/add_grad/BroadcastGradientArgs',\n",
       " u'gradients/conv_layer_1/add_grad/Sum',\n",
       " u'gradients/conv_layer_1/add_grad/Reshape',\n",
       " u'gradients/conv_layer_1/add_grad/Sum_1',\n",
       " u'gradients/conv_layer_1/add_grad/Reshape_1',\n",
       " u'gradients/conv_layer_1/add_grad/tuple/group_deps',\n",
       " u'gradients/conv_layer_1/add_grad/tuple/control_dependency',\n",
       " u'gradients/conv_layer_1/add_grad/tuple/control_dependency_1',\n",
       " u'gradients/conv_layer_1/conv2d_1_grad/Shape',\n",
       " u'gradients/conv_layer_1/conv2d_1_grad/Conv2DBackpropInput',\n",
       " u'gradients/conv_layer_1/conv2d_1_grad/Shape_1',\n",
       " u'gradients/conv_layer_1/conv2d_1_grad/Conv2DBackpropFilter',\n",
       " u'gradients/conv_layer_1/conv2d_1_grad/tuple/group_deps',\n",
       " u'gradients/conv_layer_1/conv2d_1_grad/tuple/control_dependency',\n",
       " u'gradients/conv_layer_1/conv2d_1_grad/tuple/control_dependency_1',\n",
       " u'beta1_power/initial_value',\n",
       " u'beta1_power',\n",
       " u'beta1_power/Assign',\n",
       " u'beta1_power/read',\n",
       " u'beta2_power/initial_value',\n",
       " u'beta2_power',\n",
       " u'beta2_power/Assign',\n",
       " u'beta2_power/read',\n",
       " u'conv_layer_1/W_conv_1/Adam/Initializer/zeros',\n",
       " u'conv_layer_1/W_conv_1/Adam',\n",
       " u'conv_layer_1/W_conv_1/Adam/Assign',\n",
       " u'conv_layer_1/W_conv_1/Adam/read',\n",
       " u'conv_layer_1/W_conv_1/Adam_1/Initializer/zeros',\n",
       " u'conv_layer_1/W_conv_1/Adam_1',\n",
       " u'conv_layer_1/W_conv_1/Adam_1/Assign',\n",
       " u'conv_layer_1/W_conv_1/Adam_1/read',\n",
       " u'conv_layer_1/b_conv_1/Adam/Initializer/zeros',\n",
       " u'conv_layer_1/b_conv_1/Adam',\n",
       " u'conv_layer_1/b_conv_1/Adam/Assign',\n",
       " u'conv_layer_1/b_conv_1/Adam/read',\n",
       " u'conv_layer_1/b_conv_1/Adam_1/Initializer/zeros',\n",
       " u'conv_layer_1/b_conv_1/Adam_1',\n",
       " u'conv_layer_1/b_conv_1/Adam_1/Assign',\n",
       " u'conv_layer_1/b_conv_1/Adam_1/read',\n",
       " u'conv_layer_2/W_conv_2/Adam/Initializer/zeros',\n",
       " u'conv_layer_2/W_conv_2/Adam',\n",
       " u'conv_layer_2/W_conv_2/Adam/Assign',\n",
       " u'conv_layer_2/W_conv_2/Adam/read',\n",
       " u'conv_layer_2/W_conv_2/Adam_1/Initializer/zeros',\n",
       " u'conv_layer_2/W_conv_2/Adam_1',\n",
       " u'conv_layer_2/W_conv_2/Adam_1/Assign',\n",
       " u'conv_layer_2/W_conv_2/Adam_1/read',\n",
       " u'conv_layer_2/b_conv_2/Adam/Initializer/zeros',\n",
       " u'conv_layer_2/b_conv_2/Adam',\n",
       " u'conv_layer_2/b_conv_2/Adam/Assign',\n",
       " u'conv_layer_2/b_conv_2/Adam/read',\n",
       " u'conv_layer_2/b_conv_2/Adam_1/Initializer/zeros',\n",
       " u'conv_layer_2/b_conv_2/Adam_1',\n",
       " u'conv_layer_2/b_conv_2/Adam_1/Assign',\n",
       " u'conv_layer_2/b_conv_2/Adam_1/read',\n",
       " u'fc_layer_1/W_fc_1/Adam/Initializer/zeros',\n",
       " u'fc_layer_1/W_fc_1/Adam',\n",
       " u'fc_layer_1/W_fc_1/Adam/Assign',\n",
       " u'fc_layer_1/W_fc_1/Adam/read',\n",
       " u'fc_layer_1/W_fc_1/Adam_1/Initializer/zeros',\n",
       " u'fc_layer_1/W_fc_1/Adam_1',\n",
       " u'fc_layer_1/W_fc_1/Adam_1/Assign',\n",
       " u'fc_layer_1/W_fc_1/Adam_1/read',\n",
       " u'fc_layer_1/b_fc_1/Adam/Initializer/zeros',\n",
       " u'fc_layer_1/b_fc_1/Adam',\n",
       " u'fc_layer_1/b_fc_1/Adam/Assign',\n",
       " u'fc_layer_1/b_fc_1/Adam/read',\n",
       " u'fc_layer_1/b_fc_1/Adam_1/Initializer/zeros',\n",
       " u'fc_layer_1/b_fc_1/Adam_1',\n",
       " u'fc_layer_1/b_fc_1/Adam_1/Assign',\n",
       " u'fc_layer_1/b_fc_1/Adam_1/read',\n",
       " u'fc_layer_2/W_fc_2/Adam/Initializer/zeros',\n",
       " u'fc_layer_2/W_fc_2/Adam',\n",
       " u'fc_layer_2/W_fc_2/Adam/Assign',\n",
       " u'fc_layer_2/W_fc_2/Adam/read',\n",
       " u'fc_layer_2/W_fc_2/Adam_1/Initializer/zeros',\n",
       " u'fc_layer_2/W_fc_2/Adam_1',\n",
       " u'fc_layer_2/W_fc_2/Adam_1/Assign',\n",
       " u'fc_layer_2/W_fc_2/Adam_1/read',\n",
       " u'fc_layer_2/b_fc_2/Adam/Initializer/zeros',\n",
       " u'fc_layer_2/b_fc_2/Adam',\n",
       " u'fc_layer_2/b_fc_2/Adam/Assign',\n",
       " u'fc_layer_2/b_fc_2/Adam/read',\n",
       " u'fc_layer_2/b_fc_2/Adam_1/Initializer/zeros',\n",
       " u'fc_layer_2/b_fc_2/Adam_1',\n",
       " u'fc_layer_2/b_fc_2/Adam_1/Assign',\n",
       " u'fc_layer_2/b_fc_2/Adam_1/read',\n",
       " u'Adam/learning_rate',\n",
       " u'Adam/beta1',\n",
       " u'Adam/beta2',\n",
       " u'Adam/epsilon',\n",
       " u'Adam/update_conv_layer_1/W_conv_1/ApplyAdam',\n",
       " u'Adam/update_conv_layer_1/b_conv_1/ApplyAdam',\n",
       " u'Adam/update_conv_layer_2/W_conv_2/ApplyAdam',\n",
       " u'Adam/update_conv_layer_2/b_conv_2/ApplyAdam',\n",
       " u'Adam/update_fc_layer_1/W_fc_1/ApplyAdam',\n",
       " u'Adam/update_fc_layer_1/b_fc_1/ApplyAdam',\n",
       " u'Adam/update_fc_layer_2/W_fc_2/ApplyAdam',\n",
       " u'Adam/update_fc_layer_2/b_fc_2/ApplyAdam',\n",
       " u'Adam/mul',\n",
       " u'Adam/Assign',\n",
       " u'Adam/mul_1',\n",
       " u'Adam/Assign_1',\n",
       " u'Adam',\n",
       " u'ArgMax/dimension',\n",
       " u'ArgMax',\n",
       " u'ArgMax_1/dimension',\n",
       " u'ArgMax_1',\n",
       " u'Equal',\n",
       " u'Cast',\n",
       " u'Const',\n",
       " u'Mean',\n",
       " u'init']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_kernel",
   "language": "python",
   "name": "tf_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
