{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "1. A linear regression example\n",
    "    - Declare variables in tensorflow\n",
    "    - Run session\n",
    "    - Extract results\n",
    "2. A non-linear regression example\n",
    "    - Add layers\n",
    "    - Visualize results\n",
    "3. Tensorboard\n",
    "    - Visualize your neural network\n",
    "    - Collect summaries during training\n",
    "    \n",
    "Ref:\n",
    "\n",
    "- [A series of vedios](https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. A linear regression example\n",
    "\n",
    "First we consider building a simple linear regression model with $N$ data samples:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Y = X\\beta + \\alpha + \\epsilon,\n",
    "\\end{aligned}\n",
    "$$\n",
    "where:\n",
    "\n",
    "- $Y\\in \\mathbb{R}^{N}$ is the response\n",
    "- $X\\in \\mathbb{R}^{N}$ is the only covatiate\n",
    "- $\\alpha$ and $\\beta$ are the regression coefficients\n",
    "- $\\epsilon$ is the noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the data for training. Here we consider $\\alpha=0.3$ and $\\beta=0.1$. That is, the model would be $Y=0.1X+0.3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# number of data samples\n",
    "N = 100\n",
    "alpha = 0.3\n",
    "beta = 0.1\n",
    "\n",
    "# create data for Y = 0.1X + 0.3\n",
    "x_data = np.random.rand(N)\n",
    "y_data = x_data*beta + alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we would feed these data into the tensorflow structure. These include:\n",
    "\n",
    "- Declare variables\n",
    "- Setup optimization object function and optimizer\n",
    "- Run and get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declare variables\n",
    "beta = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "alpha = tf.Variable(tf.zeros([1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two tensorflow variables: *alpha* and *beta*. We also specify the the methods of initializing these two variables:\n",
    "\n",
    "**tf.random_uniform([1], -1.0, 1.0)** would return an array of random number with length 1 from a uniform distribution between -1 nad 1. This first argument specify the number of random number would be generated. \n",
    "\n",
    "**tf.zeros([1])** would return an array of zeros with length 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# relation between input and output\n",
    "y_hat = x_data*beta + alpha\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.square(y_hat-y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training stage, Tensorflow would update **alpha** and **beta**. And we are trying to minimize the loss, where loss is mean squared error:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "loss = \\frac{1}{N}\\sum_{n=1}^N (\\hat{y}_n-y_n)^2\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create optimizer, set step size to be 0.5\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.5) \n",
    "\n",
    "# The object fuction is to minimize the mean squared loss\n",
    "obj = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all of the tensorflow structure ready, we can start to traing our model:\n",
    "\n",
    "- Initialization\n",
    "- Create and run codes using session\n",
    "- Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:0, alpha:0.649393, beta:-0.217745\n",
      "Step:20, alpha:0.362950, beta:-0.017989\n",
      "Step:40, alpha:0.318926, beta:0.064527\n",
      "Step:60, alpha:0.305690, beta:0.089335\n",
      "Step:80, alpha:0.301711, beta:0.096794\n",
      "Step:100, alpha:0.300514, beta:0.099036\n",
      "Step:120, alpha:0.300155, beta:0.099710\n",
      "Step:140, alpha:0.300046, beta:0.099913\n",
      "Step:160, alpha:0.300014, beta:0.099974\n",
      "Step:180, alpha:0.300004, beta:0.099992\n",
      "Step:200, alpha:0.300001, beta:0.099998\n"
     ]
    }
   ],
   "source": [
    "# initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# create a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# run the initializer\n",
    "sess.run(init)\n",
    "\n",
    "# run optimization and print results\n",
    "for step in range(201):\n",
    "    sess.run(obj)\n",
    "    if step % 20 == 0:\n",
    "        print(\"Step:%d, alpha:%f, beta:%f\" % \n",
    "              (step, sess.run(alpha), sess.run(beta)))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two ways of using session\n",
    "\n",
    "Method 1 is just he code we have seen above. Remember to close the session with **sess.close()**.\n",
    "\n",
    "Method 2 uses the **with** statement. You should get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:0, alpha:0.375403, beta:0.162019\n",
      "Step:20, alpha:0.297714, beta:0.104116\n",
      "Step:40, alpha:0.299389, beta:0.101100\n",
      "Step:60, alpha:0.299837, beta:0.100294\n",
      "Step:80, alpha:0.299956, beta:0.100079\n",
      "Step:100, alpha:0.299988, beta:0.100021\n",
      "Step:120, alpha:0.299997, beta:0.100006\n",
      "Step:140, alpha:0.299999, beta:0.100001\n",
      "Step:160, alpha:0.300000, beta:0.100000\n",
      "Step:180, alpha:0.300000, beta:0.100000\n",
      "Step:200, alpha:0.300000, beta:0.100000\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(201):\n",
    "        sess.run(obj)\n",
    "        if step % 20 == 0:\n",
    "            print(\"Step:%d, alpha:%f, beta:%f\" % \n",
    "                  (step, sess.run(alpha), sess.run(beta)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholder\n",
    "\n",
    "There is a special type of variable called placeholder. This allows you to construct the network first and feed the data afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output:14.000000\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"Output:%f\" % sess.run(output, \n",
    "                                feed_dict={input1:[7], input2:[2]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare these two lines\n",
    "```python\n",
    "y_hat = x_data*beta + alpha\n",
    "output = tf.multiply(input1, input2)\n",
    "```\n",
    "The first line comes from the linear regression example. In this line, the value of **x_data** is predetermined. However, the value of **input1** and **input2** are not unkown until we feed the data when running the session. With placeholder, we could feed different data to the same network without defining the tensorflow structure again. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. A non-linear regression example\n",
    "\n",
    "In this example, we would consider a quadratic realtion between $X$ and $Y$. Several key factors in this example:\n",
    "\n",
    "- A function for adding layers\n",
    "- Use placeholder for flexibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The *add_layer* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(x, in_size, out_size, activation_function=None):\n",
    "    W = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    # it is recommended not initialize not to zero\n",
    "    b = tf.Variable(tf.zeros([1, out_size]) + 0.1) \n",
    "    Wx_b = tf.matmul(x, W) + b\n",
    "    \n",
    "    if activation_function is None:\n",
    "        output = Wx_b\n",
    "    else:\n",
    "        output = activation_function(Wx_b)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does the function do:\n",
    "- Create a layer with input length = *in_size*, output length = *out_size*.\n",
    "- If specified, the activation function would be applied on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate data samples\n",
    "N = 300\n",
    "x_data = np.linspace(-1, 1, N)[:, np.newaxis]\n",
    "y_data = np.square(x_data) - 0.87 \\\n",
    "            + np.random.normal(0, 0.05, x_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we generate our data $X$from -1 to 1. By using *[:, np.newaxis]*, we would obtain *x_data* as an array with shape (N, 1). Data $Y$ is generated according to the relationship:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "Y = X^2 - 0.87 + \\epsilon\n",
    "\\end{aligned}\n",
    "$$\n",
    "Note that we are still using linear function inside the neural network and we will see how neural network combines several linear functions and activation functions to approximate a non-linear relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholder for the tensorflow\n",
    "x_input = tf.placeholder(tf.float32, [None, 1])\n",
    "y_input = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "layer1_output_size = 10\n",
    "layer1 = add_layer(x_input, 1, layer1_output_size, \n",
    "                   activation_function=tf.nn.relu)\n",
    "y_hat = add_layer(layer1, layer1_output_size, 1, activation_function=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider there are 10 neurons in the hidden layer (*layer1*). Thus, for *layer1*, the input size is 1 and the ouptput size is 10. The output of *layer1* would serve as the input of the output layer. Thus, the input size is 10 and the final output is the predicted value (*y_hat*) with size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "loss = tf.reduce_mean(tf.square(y_hat-y_input))\n",
    "\n",
    "# optimization object function\n",
    "obj = tf.train.GradientDescentOptimizer(0.1).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like the linear regression example, we adopt mean squared error as the loss function and create a optimizer for minimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:0, loss:0.309368\n",
      "Step:100, loss:0.008168\n",
      "Step:200, loss:0.006041\n",
      "Step:300, loss:0.005412\n",
      "Step:400, loss:0.005126\n",
      "Step:500, loss:0.004926\n",
      "Step:600, loss:0.004782\n",
      "Step:700, loss:0.004659\n",
      "Step:800, loss:0.004562\n",
      "Step:900, loss:0.004472\n",
      "Step:1000, loss:0.004394\n"
     ]
    }
   ],
   "source": [
    "# initializer\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# start a session to run\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(1001):\n",
    "        sess.run(obj, feed_dict={x_input: x_data, \n",
    "                                 y_input: y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(\"Step:%d, loss:%f\" % \n",
    "                  (step, sess.run(loss, \n",
    "                                  feed_dict={x_input: x_data, \n",
    "                                             y_input: y_data})))\n",
    "            \n",
    "    # obtain the final y_hat\n",
    "    y_hat = sess.run(y_hat, feed_dict={x_input: x_data,\n",
    "                                       y_input: y_data})\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we use placeholder *x_input* and *y_input* when construsting the neural network. Now we have to feed in the data using *feed\\_dict*. Note that when extracting the value of *loss*, we should provide *feed\\_dict* as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIsJfEAQhDPl/QDZrBLlpzGEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117c87c10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a quick visualization\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.subplot(111)\n",
    "plt.scatter(x_data, y_data)\n",
    "plt.plot(x_data, y_hat, 'r-', lw=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: If you get a bad results or the values cannot converge, try to change the step size of the gradient descent optimizer. Step size = 0.1 should be fine in this example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Visualization using tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard is a useful tool for checking and visualizing your learning procedures. We would consider two useful information tensorboard could provid:\n",
    "\n",
    "- Viasualize your neural network graph\n",
    "- Obtain summaries from the training procedure\n",
    "\n",
    "For more details, check https://www.tensorflow.org/get_started/summaries_and_tensorboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a graph of the neural network is simple. You just have to name all the variables accordingly and tensorboard would automatically generate the graph for you.\n",
    "\n",
    "Extracting the summaries during the learning procedure is just as simple as creating the graph: you specify which variables you are interested in and tensorboard will do the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "def add_named_layer(x, in_size, out_size, n_layer, activation_function=None):\n",
    "    layer_name = \"layer%s\" % n_layer\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope(\"W\"):\n",
    "            W = tf.Variable(tf.random_normal([in_size, out_size]), name=\"W\")\n",
    "            tf.summary.histogram(layer_name+\"/W\", W)\n",
    "        with tf.name_scope(\"b\"):\n",
    "            b = tf.Variable(tf.zeros([1, out_size]) + 0.1, name=\"b\") \n",
    "            tf.summary.histogram(layer_name+\"/b\", b)\n",
    "        with tf.name_scope(\"Wx_b\"):\n",
    "            Wx_b = tf.add(tf.matmul(x, W), b)\n",
    "\n",
    "        if activation_function is None:\n",
    "            output = Wx_b\n",
    "        else:\n",
    "            output = activation_function(Wx_b)\n",
    "            tf.summary.histogram(layer_name+\"/output\", output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a new function called *add_named_layer*. The function is slightly different from the previous one: you need to provide a number for nameing the layer.\n",
    "\n",
    "The code\n",
    "\n",
    "```python\n",
    "with tf.name_scope(your_scope_name):\n",
    "```\n",
    "\n",
    "tells tensorboard how do you want to call the container and the objects within the *with* statement would be included inside the container.\n",
    "\n",
    "This is how *layer1* looks like\n",
    "![Image of layer 1](figs/01_tensorboard_layer.png)\n",
    "\n",
    "\n",
    "To collect learning summaries, we use\n",
    "```python\n",
    "tf.summary.histogram(histogram_name, variable_name)\n",
    "```\n",
    "Note that we use **tf.summary.histogram** for vectors. As for scalar, we would use **tf.summary.scalar**. We will see this in a minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 300\n",
    "x_data = np.linspace(-1, 1, N)[:, np.newaxis]\n",
    "y_data = np.square(x_data) - 0.87 \\\n",
    "            + np.random.normal(0, 0.05, x_data.shape)\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    x_input = tf.placeholder(tf.float32, [None, 1], name=\"x_input\")\n",
    "    y_input = tf.placeholder(tf.float32, [None, 1], name=\"y_input\")\n",
    "\n",
    "layer1 = add_named_layer(x_input, 1, 10, n_layer=1, activation_function=tf.nn.relu)\n",
    "prediction = add_named_layer(layer1, 10, 1, n_layer=2, activation_function=None)\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.reduce_sum(tf.square(y_input - prediction), \n",
    "                         reduction_indices=[1]))\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "with tf.name_scope(\"train\"):\n",
    "    obj = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n",
    "\n",
    "    \n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    sess.run(obj, \n",
    "            feed_dict={x_input: x_data, y_input: y_data})\n",
    "    if i % 50 == 0:\n",
    "        result = sess.run(merged, feed_dict={x_input: x_data, y_input: y_data})    \n",
    "        writer.add_summary(result, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: you might want to reset python kernel if you encounter errors**\n",
    "\n",
    "Most of the codes are simiar, we just have to add several lines to finish the neural network structure and collect the summaries.\n",
    "\n",
    "When everthing is all set, we want to merge every result. This includes graph and summaries. This is done by \n",
    "\n",
    "```python\n",
    "merged = tf.summary.merge_all()\n",
    "```\n",
    "\n",
    "We also need a filewriter provided by tensorflow:\n",
    "```python\n",
    "writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
    "```\n",
    "This would create a file writer and the collected information would be written in the folder named *logs*. The neural network graph is passed using *sess.graph*.\n",
    "\n",
    "Finally, we run tensorflow as usual and collect summaries using\n",
    "\n",
    "```python\n",
    "writer.add_summary(result, i)\n",
    "```\n",
    "\n",
    "### Launch tensorboard\n",
    "\n",
    "To launch tensorboard, open a terminal and change directory to the parent path where you save the information. In our example if the folder *logs* located under *~/*, then we will do\n",
    "\n",
    "```shell\n",
    "cd ~/\n",
    "tensorboard --logdir='logs/'\n",
    "\n",
    "```\n",
    "Next, open your browser and type in *http://localhost:6006/*. You can see the information collected by tensorflow."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_kernel",
   "language": "python",
   "name": "tf_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
