{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "\n",
    "1. The MNIST dataset\n",
    "2. Classification using neural network\n",
    "3. Classification using CNN\n",
    "\n",
    "Ref: \n",
    "\n",
    "- [Tensorflow turotial 1](https://www.tensorflow.org/get_started/mnist/beginners)\n",
    "- [Tensorflow turotial 2](https://www.tensorflow.org/get_started/mnist/pros)\n",
    "- [A series of video](https://morvanzhou.github.io/tutorials/machine-learning/tensorflow/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The MNIST dataset\n",
    "\n",
    "In this note we would use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) for the classification task. The MNIST dataset consists of hand-written images from 0 to 9. For each observation, we have an image with 28 pixels by 28 pixels associated with its label, which is the digit shown in the image. \n",
    "\n",
    "The image looks like this:\n",
    "![image_9487](figs/02_9487.png)\n",
    "\n",
    "In fact, every image is flatted to a 1-D vector so that a 28x28 image would become 1x784. \n",
    "\n",
    "The label is stored using a one-hot vector. There are 10 possible outcomes (from 0 to 9) and thus the length of this vector is 10. The entry would be 1 if the image belongs to class this entry representing and the other entries would be zero. For example, if 2 is shown in the image, the corresponding label vector would be [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]. Note that the representation starts from 0.\n",
    "\n",
    "There are 3 parts in this dataset: 60,000 samples for learning the model (split to 55,000 training and 5,000 validation) and 10,000 testing samples. The input size is 784 and the output size is 10. Here we provide some codes for checking the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, load the dataset using the function provided by the tensorflow tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# download MNIST dataset first\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would download the dataset if you do not have the files under your working directory. These files would be extracted automatically. We could access the data through variable **mnist**.\n",
    "\n",
    "Here are some useful dataset under **mnist**.\n",
    "\n",
    "- mnist.train.images: the training image with size 55000 x 784\n",
    "- mnist.train.labels: the training label with size 55000 x 10\n",
    "- mnist.test.images: the testing image with size 10000 x 784\n",
    "- mnist.test.labels: the testing label with size 10000 x 10\n",
    "- mnist.validation.images: the validation image with size 5000 x 784\n",
    "- mnist.validation.labels: the validation label with size 5000 x 784 \n",
    "\n",
    "We could check the size with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image size 55000x784\n",
      "Train label size 55000x10\n"
     ]
    }
   ],
   "source": [
    "trainImgShape = mnist.train.images.shape\n",
    "print(\"Train image size {}x{}\".format(trainImgShape[0], trainImgShape[1]))\n",
    "\n",
    "trainLabelShape = mnist.train.labels.shape\n",
    "print(\"Train label size {}x{}\".format(trainLabelShape[0], trainLabelShape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could check the size of images labels of other parts by changing the variables you are interested in.\n",
    "\n",
    "Next, we would like to inspect the images and corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117125b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# the data we are interested in\n",
    "imgData = mnist.train.images\n",
    "labelData = mnist.train.labels\n",
    "    \n",
    "# the date ID    \n",
    "dataID = 1\n",
    "# reshape the image to 2D (28x28)\n",
    "img2D = np.reshape(imgData[dataID, :], (28,28))\n",
    "# plot the image\n",
    "plt.imshow(img2D, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# the corresponding label vector\n",
    "print(labelData[dataID, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classification using neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would consider a simple neural network with one hidden layer. Using the provided information, we know that the input size for the hidden layer would be 784 and the output size for the hidden layer would be 10.\n",
    "\n",
    "Recall the *add_layer* function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_layer(x, in_size, out_size, activation_function=None):\n",
    "    W = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    # it is recommended not initialize not to zero\n",
    "    b = tf.Variable(tf.zeros([1, out_size]) + 0.1) \n",
    "    Wx_b = tf.matmul(x, W) + b\n",
    "    \n",
    "    if activation_function is None:\n",
    "        output = Wx_b\n",
    "    else:\n",
    "        output = activation_function(Wx_b)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we could build the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_input = tf.placeholder(tf.float32, [None, 784])\n",
    "y_input = tf.placeholder(tf.float32, [None, 10])\n",
    "# output layer\n",
    "y_hat = add_layer(x_input, 784, 10, activation_function=tf.nn.softmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use [softmax](https://en.wikipedia.org/wiki/Softmax_function) as the activation funciton. The softmax function is a common choice for doing classification for it has some nice properties (like it is differentiable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_input * tf.log(y_hat),\n",
    "                                              reduction_indices=[1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different from the regression, here we use the so-call [cross-entropy](https://en.wikipedia.org/wiki/Cross_entropy) as our loss function. The cross-entropy is defined as \n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\text{Cross-entropy} = -\\sum_{n} y_n\\log(\\hat{y}_n),\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $y_n$ is the true distribution for data $n$ and $\\hat{y}_n$ is the predicted distribution. Note that we could treat $y_n$ as following a multinomial distribution. The cross-entropy is a measure of how close the true distribution and the predicted distribution is.\n",
    "\n",
    "And then we would use gradient descent to minimize the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "obj = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we jump to the training step, we would like to add addition layers to our network for computing the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_pred = tf.equal(tf.argmax(y_input,1), tf.argmax(y_hat,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable **y_hat** we obtained from the output layber would be a vector with length 10. Values in each entry represent the likelihood (or probability after normalization) of being classified to different classes. Thus, we could choose the class with the highest likelihood as our prediction. The could be done using the function **tf.argmax**.  Same deal for the true label vector since there is only one 1 in the vector and other entries are zero. Finally, we compare the prediction to the true class using **tf.equal**. If we predict the image correctly, **correct_pred** would be True, otherwise it would be False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute accuracy, we have to cast the boolean to floating points. This would convert True to 1 and False to 0. The average of a series of 0, 1 would give us the proportion of 1, which is the accuracy as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we initilize and start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0921\n",
      "0.6364\n",
      "0.7317\n",
      "0.7764\n",
      "0.7957\n",
      "0.8173\n",
      "0.8268\n",
      "0.8337\n",
      "0.8407\n",
      "0.8415\n",
      "0.8524\n",
      "0.8567\n",
      "0.8615\n",
      "0.8634\n",
      "0.8619\n",
      "0.8663\n",
      "0.8699\n",
      "0.8706\n",
      "0.8731\n",
      "0.871\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "# initialization\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_img, batch_label = mnist.train.next_batch(100)\n",
    "    sess.run(obj, feed_dict={x_input: batch_img, y_input: batch_label})\n",
    "    if i% 50 == 0:\n",
    "        print(sess.run(accuracy, \n",
    "                       feed_dict={x_input: mnist.test.images, \n",
    "                                  y_input: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8734\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(accuracy, \n",
    "                       feed_dict={x_input: mnist.test.images, \n",
    "                                  y_input: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the tutorial it is stated that this is numerically unstable. Instead, the function [tf.nn.softmax_cross_entropy_with_logits](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits) is recommended. This function should be applied on the unnormalized logits. That is, this function would serve as the activation function and the loss function combined together. To apply this function, we cannot use **add_layer**  or we cannot get the prediction. Let's re-construct our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_input = tf.placeholder(tf.float32, [None, 784])\n",
    "y_input = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# hidden layer\n",
    "in_size = 784\n",
    "out_size = 10\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([1, out_size])+0.1) \n",
    "Wx_b = tf.matmul(x_input, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable **Wx_b** is the unnormalized logits. Thus, the cross_entropy now becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = \\\n",
    "    tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=y_input,\n",
    "                                                logits=Wx_b))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get **y_hat**, simply apply tf.nn.softmax on **Wx_b**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = tf.nn.softmax(Wx_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the codes are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4333\n",
      "0.8697\n",
      "0.8944\n",
      "0.8983\n",
      "0.9064\n",
      "0.9035\n",
      "0.9113\n",
      "0.9114\n",
      "0.9107\n",
      "0.914\n",
      "0.911\n",
      "0.9137\n",
      "0.9161\n",
      "0.9173\n",
      "0.9155\n",
      "0.9179\n",
      "0.9129\n",
      "0.9181\n",
      "0.9178\n",
      "0.9187\n"
     ]
    }
   ],
   "source": [
    "obj = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "correct_pred = tf.equal(tf.argmax(y_input,1), tf.argmax(y_hat,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "# initialization\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "    batch_img, batch_label = mnist.train.next_batch(100)\n",
    "    sess.run(obj, feed_dict={x_input: batch_img, y_input: batch_label})\n",
    "    if i% 50 == 0:\n",
    "        print(sess.run(accuracy, \n",
    "                       feed_dict={x_input: mnist.test.images, \n",
    "                                  y_input: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy rate is about 91.7%. If you compare to the previous result, you'll see they are quite different. As I checked the tutorial, it is stated that the prediction accuracy should be around 92% (from the tensorflow tutorial), which agrees with the second result. After comparing codes for a while, I realize that the first code does not get to the best solution. If we change the step number to a larger number, say, 10000, we could obtain the accuracy rate about 92% as well. The main difference between the first and the second version is how we initialize the weight matrix **W**. We use Gaussian random number to initialize in the first version and set to a zeroe matrix in the second version. It seems that setting to zeroes would be a better initialization practice, at least in this dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Classification using CNN\n",
    "\n",
    "The 92% prediction accuracy seems good, but not good enough. [This website] (http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html) shows some recent literature of the prediction performance. It seems like it is possible to reach the accuracy rate of 99% or higher. \n",
    "\n",
    "Now we would implement a Convolution Neural Network (CNN) using tensorflow. CNN is a popular approach to handle image inputs. For more details about CNN, see [this vedio from standord lecture](https://www.youtube.com/watch?v=AQirPKrAyDg) and [this webpage](http://cs231n.github.io/convolutional-networks/).\n",
    "\n",
    "Consider a simple CNN:\n",
    "![cnnGraph](figs/02_cnnGraph.png)\n",
    "\n",
    "Here are several important components:\n",
    "\n",
    "1. Convolution (**conv_1** and **conv_2**): This adopts a [2D convolution](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d) between weighted matrix **W** and then we add a bias **b** to the output. For this component we need to decide the patch size (5x5 in both components) and the output size (32 for **conv_1** and 64 for **conv_2**). \n",
    "2. Rectified linear unit (**ReLU_1** and **ReLU_2**): This is an activation function.  \n",
    "3. Max pooling (pool_1 and pool_2): Here we adopt a [2x2 max pooling](https://www.tensorflow.org/api_docs/python/tf/nn/max_pool).\n",
    "4. Fully-connected layer (**fc_1** and **fc_2**): This part is similar to the neural network we have seen before. We first reduce the length to 1024 at **fc_1** and then further reduce the length to 10 (the length of the label vector) at **fc_2**.\n",
    "5. Dropout: This design intent to [prevent overfitting](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf). But at pointed out in the tutorial, since we are using a small convolution network the performance would be identical with and without dropout.\n",
    "6. Softmax: Similar to the previous example, we compute the softmax to obtain the likelihood of the input image being classified to each class.\n",
    "\n",
    "Let's start from scratch. Clear all the things first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "# Note: this would clear all the variables and functions\n",
    "# use %reset -f  to avoid asking\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "#load data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function for createing parametering in the convolution component. Note that it is suggested to initialize the parameters with small noise (or small offset) instead of 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For performing convolution, we choose strides to be 1 and use zeo padding to force the output to be the same size as input. A commonly used 2x2 max pooling is adopted here. Check [here](http://cs231n.github.io/convolutional-networks/) for more details about strides and polling.\n",
    "\n",
    "Now we are ready to build our CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input variables\n",
    "x_input = tf.placeholder(tf.float32, [None, 784])\n",
    "y_input = tf.placeholder(tf.float32, [None, 10])\n",
    "x_img_input = tf.reshape(x_input, [-1, 28, 28, 1])\n",
    "\n",
    "# dropout setting\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create placeholder for the inputs. Note that the original data is flattened to 1x784 and thus we have to reshape them back to 28x28. The variable **keep_prob** is the keep probability setting for the dropout operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for conv_1\n",
    "W_conv_1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv_1 = bias_variable([32])\n",
    "\n",
    "conv_1 = conv2d(x_img_input, W_conv_1) + b_conv_1\n",
    "ReLU_1 = tf.nn.relu(conv_1)\n",
    "pool_1 = max_pool_2x2(ReLU_1)\n",
    "\n",
    "# parameters for conv_2\n",
    "W_conv_2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv_2 = bias_variable([64])\n",
    "\n",
    "conv_2 = conv2d(pool_1, W_conv_2) + b_conv_2\n",
    "ReLU_2 = tf.nn.relu(conv_2)\n",
    "pool_2 = max_pool_2x2(ReLU_2)\n",
    "\n",
    "reshape = tf.reshape(pool_2, [-1, 7*7*64])\n",
    "\n",
    "# parameters for fc_1\n",
    "W_fc_1 = weight_variable([7*7*64, 1024])\n",
    "b_fc_1 = bias_variable([1024])\n",
    "fc_1 = tf.matmul(reshape, W_fc_1) + b_fc_1\n",
    "ReLU_3 = tf.nn.relu(fc_1)\n",
    "dropout = tf.nn.dropout(ReLU_3, keep_prob)\n",
    "\n",
    "# parameters for fc_2\n",
    "W_fc_2 = weight_variable([1024, 10])\n",
    "b_fc_2 = bias_variable([10])\n",
    "# output of fc_2\n",
    "y_logits = tf.matmul(dropout, W_fc_2) + b_fc_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y_input, \n",
    "                                            logits=y_logits))\n",
    "# minimizaer to minimize cross_entropy\n",
    "obj = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# calculate prediction accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(y_logits, 1), \n",
    "                              tf.argmax(y_input, 1)  )\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that here we use **tf.nn.softmax_cross_entropy_with_logits** and thus we ouput **y_logits** instead of applying softmax on it. Here we choose a different optimizer. See [here](https://www.tensorflow.org/api_guides/python/train#Optimizers) for more details.\n",
    "\n",
    "Now we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.086\n",
      "0.5933\n",
      "0.7617\n",
      "0.8336\n",
      "0.8651\n",
      "0.8824\n",
      "0.897\n",
      "0.9103\n",
      "0.9201\n",
      "0.9226\n",
      "0.9302\n",
      "0.932\n",
      "0.9386\n",
      "0.9373\n",
      "0.9428\n",
      "0.9448\n",
      "0.9455\n",
      "0.9465\n",
      "0.9507\n",
      "0.9525\n"
     ]
    }
   ],
   "source": [
    "# start session and run\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "        batch_img, batch_label = mnist.train.next_batch(100)\n",
    "        sess.run(obj, feed_dict={x_input: batch_img, \n",
    "                                 y_input: batch_label, \n",
    "                                 keep_prob: 0.5} )\n",
    "        if i % 50 == 0:\n",
    "            print(sess.run(accuracy, \n",
    "                           feed_dict={x_input: mnist.test.images, \n",
    "                                      y_input: mnist.test.labels,\n",
    "                                      keep_prob: 0.5}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes my laptop about 10 minutes to finish 1000 training steps. It is claimed in the tutorial that the accuracy could reach 99%. You could try to increase the step numbers to see if you can get to this high accuracy rate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_kernel",
   "language": "python",
   "name": "tf_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
